{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the images of Effected and uneffected images\n",
    "X=[]\n",
    "Y=[]\n",
    "path='F://Project//virus//Uneffected'\n",
    "for img in os.listdir(path):\n",
    "    try:\n",
    "        img1 = cv2.imread(os.path.join(path,img))\n",
    "        X.append(np.array(img1))\n",
    "        Y.append(0)\n",
    "    except :\n",
    "        pass\n",
    "path='F://Project//virus//Effected'\n",
    "for img in os.listdir(path):\n",
    "    try:\n",
    "        img1 = cv2.imread(os.path.join(path,img))\n",
    "        X.append(np.array(img1))\n",
    "        Y.append(1)\n",
    "    except :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 24, 16, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 24, 16, 12)   336         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 24, 16, 12)   48          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 24, 16, 12)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 12, 8, 12)    0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 24, 16, 32)   4736        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 12, 8, 20)    2180        max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 24, 16, 32)   128         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 12, 8, 20)    0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 24, 16, 32)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 12, 8, 20)    80          dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 6, 4, 32)     0           dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 6, 4, 20)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 6, 4, 52)     0           max_pooling2d_20[0][0]           \n",
      "                                                                 max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 6, 4, 64)     30016       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 6, 4, 64)     0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 6, 4, 64)     256         dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 3, 2, 64)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 384)          0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 32)           12320       flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 32)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32)           128         dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           528         batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 16)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16)           64          dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 2)            34          batch_normalization_29[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 50,854\n",
      "Trainable params: 50,502\n",
      "Non-trainable params: 352\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#CNN code for our images.\n",
    "[width,height,channel]=[24,16,3]    # Size of images to feed in CNN.\n",
    "\n",
    "# Conv2D is convolution layer provide convolution of image by intializing the kernel.\n",
    "# BatchNormalization is used to normalize the feature maps get after convolution layer.\n",
    "# Dropout layer drop some neurons in the network make network not to overfit.\n",
    "# MaxPooling and AvgPooling are pooling using the given size.\n",
    "\n",
    "inputs = tf.keras.layers.Input((width,height,channel))\n",
    "\n",
    "c1=tf.keras.layers.Conv2D(12,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',kernel_regularizer=tf.keras.regularizers.l1_l2(0.01,0.001))(inputs)\n",
    "c1=tf.keras.layers.BatchNormalization(axis=-1)(c1)\n",
    "c1=tf.keras.layers.Dropout(0.1)(c1)\n",
    "p1=tf.keras.layers.MaxPooling2D((2,2))(c1)\n",
    "\n",
    "c2=tf.keras.layers.Conv2D(20,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',kernel_regularizer=tf.keras.regularizers.l1_l2(0.01,0.001))(p1)\n",
    "c2=tf.keras.layers.Dropout(0.2)(c2)\n",
    "c2=tf.keras.layers.BatchNormalization(axis=-1)(c2)\n",
    "p2=tf.keras.layers.MaxPooling2D((2,2))(c2)\n",
    "\n",
    "c3=tf.keras.layers.Conv2D(32,(7,7),activation='relu',kernel_initializer='he_normal',padding='same',kernel_regularizer=tf.keras.regularizers.l1_l2(0.01,0.001))(inputs)\n",
    "c3=tf.keras.layers.BatchNormalization(axis=-1)(c3)\n",
    "c3=tf.keras.layers.Dropout(0.4)(c3)\n",
    "p5=tf.keras.layers.AveragePooling2D((4,4))(c3)\n",
    "\n",
    "p3=tf.keras.layers.concatenate([p5, p2])\n",
    "\n",
    "p3=tf.keras.layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same',kernel_regularizer=tf.keras.regularizers.l1_l2(0.01,0.001))(p3)\n",
    "p3=tf.keras.layers.Dropout(0.2)(p3)\n",
    "p3=tf.keras.layers.BatchNormalization(axis=-1)(p3)\n",
    "p3=tf.keras.layers.MaxPooling2D((2,2))(p3)\n",
    "\n",
    "p3=tf.keras.layers.Flatten()(p3)\n",
    "p4= tf.keras.layers.Dense(32,activation='sigmoid',kernel_regularizer=tf.keras.regularizers.l1_l2(0.01,0.001))(p3)\n",
    "p4=tf.keras.layers.Dropout(0.2)(p4)\n",
    "p4=tf.keras.layers.BatchNormalization(axis=-1)(p4)\n",
    "\n",
    "p4= tf.keras.layers.Dense(16,activation='sigmoid',kernel_regularizer=tf.keras.regularizers.l1_l2(0.01,0.001))(p4)\n",
    "p4=tf.keras.layers.Dropout(0.2)(p4)\n",
    "p4=tf.keras.layers.BatchNormalization(axis=-1)(p4)\n",
    "output=tf.keras.layers.Dense(2,activation='softmax')(p4)\n",
    "\n",
    "model=tf.keras.Model(inputs=inputs,outputs=output)\n",
    "opt=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.99, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam')\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using early stopping to stop the model earlyif validation loss become constant\n",
    "checkpoint=tf.keras.callbacks.ModelCheckpoint('F://Project//virus//Uneffected//vius_clss.h5',verbose=1,save_best_only=True)\n",
    "callbacks=[tf.keras.callbacks.EarlyStopping(patience=2,monitor='val_loss')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 277995 samples, validate on 69499 samples\n",
      "Epoch 1/10\n",
      "277995/277995 [==============================] - 594s 2ms/sample - loss: 1.0810 - accuracy: 0.6840 - val_loss: 0.6683 - val_accuracy: 0.6916\n",
      "Epoch 2/10\n",
      "277995/277995 [==============================] - 556s 2ms/sample - loss: 0.6692 - accuracy: 0.6901 - val_loss: 0.6680 - val_accuracy: 0.6916\n",
      "Epoch 3/10\n",
      "277995/277995 [==============================] - 552s 2ms/sample - loss: 0.6696 - accuracy: 0.6901 - val_loss: 0.6683 - val_accuracy: 0.6916\n",
      "Epoch 4/10\n",
      "277995/277995 [==============================] - 559s 2ms/sample - loss: 0.6702 - accuracy: 0.6901 - val_loss: 0.6697 - val_accuracy: 0.6916\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test=train_test_split(X, to_categorical(np.array(Y)),test_size=0.2,random_state=0)\n",
    "history= model.fit(np.array(X_train),Y_train, batch_size=50,verbose=1,epochs=10,validation_split=0.2,shuffle=True,callbacks=callbacks)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
